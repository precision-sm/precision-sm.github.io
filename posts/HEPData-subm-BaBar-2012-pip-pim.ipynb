{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3874ee-a795-4b7a-ae91-dea7381f83aa",
   "metadata": {},
   "source": [
    "<!-- TEASER_END -->\n",
    "# BaBar 2012 $\\sigma(e^+e^- \\to \\pi^+ \\pi^- (\\gamma))$ HEPData submission\n",
    "\n",
    "### Paper\n",
    "\n",
    "- [Phys.Rev.D 86 (2012) 032013, 2012](https://doi.org/10.1103/PhysRevD.86.032013)\n",
    "- [InspireHEP 1114155](https://inspirehep.net/literature/1114155)\n",
    "\n",
    "### HEPData documentation for submissions\n",
    "\n",
    "- [https://hepdata-submission.readthedocs.io/en/latest/](https://hepdata-submission.readthedocs.io/en/latest/)\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- [hepdata_lib](https://github.com/HEPData/hepdata_lib) python3 library\n",
    "  - [ROOT](https://root.cern.ch) with Python3 libraries\n",
    "  - [ImageMagick](https://www.imagemagick.org)\n",
    "  - Make sure that you have `ROOT` in your `$PYTHONPATH` and that the `convert` command is available by adding its location to your `$PATH` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe9b162-0f47-41cb-8726-d0f07740d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import tempfile\n",
    "import re\n",
    "import urllib.request\n",
    "from requests.utils import requote_uri\n",
    "from array import array\n",
    "import json\n",
    "import yaml\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ac8a2e-4235-4cb3-b056-9c16a545e842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n"
     ]
    }
   ],
   "source": [
    "import hepdata_lib\n",
    "from hepdata_lib import Submission\n",
    "from hepdata_lib import Table\n",
    "from hepdata_lib import Variable, Uncertainty\n",
    "from hepdata_lib import RootFileReader\n",
    "from hepdata_lib import root_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a9462e7-0354-4a79-b0e4-9cbd9a281fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A precise measurement of the cross section of the process $e^+e^- \\\\to \\\\pi^+\\\\pi^-(\\\\gamma)$ from threshold to an energy of $3$ GeV is obtained with the initial-state radiation (ISR) method using $232$ fb$^{-1}$ of data collected with the BaBar detector at $e^+e^-$ center-of-mass energies near $10.6$ GeV. The ISR luminosity is determined from a study of the leptonic process $e^+e^-\\\\to\\\\mu^+\\\\mu^-(\\\\gamma)\\\\gamma_{\\\\rm ISR}$, which is found to agree with the next-to-leading-order QED prediction to within 1.1\\\\%. The cross section for the process $e^+e^-\\\\to\\\\pi^+\\\\pi^-(\\\\gamma)$ is obtained with a systematic uncertainty of 0.5\\\\% in the dominant $\\\\rho$ resonance region. The leading-order hadronic contribution to the muon magnetic anomaly calculated using the measured $\\\\pi\\\\pi$ cross section from threshold to $1.8$ GeV is $(514.1 \\\\pm 2.2({\\\\rm stat}) \\\\pm 3.1({\\\\rm syst}))\\\\times 10^{-10}$.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## abstract\n",
    "##\n",
    "paper_abstract = r\"\"\"A precise measurement of the cross section of the process $e^+e^- \\to\n",
    "\\pi^+\\pi^-(\\gamma)$ from threshold to an energy of $3$ GeV is obtained with the\n",
    "initial-state radiation (ISR) method using $232$ fb$^{-1}$ of data collected\n",
    "with the BaBar detector at $e^+e^-$ center-of-mass energies near $10.6$ GeV.\n",
    "The ISR luminosity is determined from a study of the leptonic process\n",
    "$e^+e^-\\to\\mu^+\\mu^-(\\gamma)\\gamma_{\\rm ISR}$, which is found to agree with the\n",
    "next-to-leading-order QED prediction to within 1.1\\%. The cross section for the\n",
    "process $e^+e^-\\to\\pi^+\\pi^-(\\gamma)$ is obtained with a systematic uncertainty\n",
    "of 0.5\\% in the dominant $\\rho$ resonance region. The leading-order hadronic\n",
    "contribution to the muon magnetic anomaly calculated using the measured\n",
    "$\\pi\\pi$ cross section from threshold to $1.8$ GeV is $(514.1 \\pm 2.2({\\rm\n",
    "stat}) \\pm 3.1({\\rm syst}))\\times 10^{-10}$.\"\"\"\n",
    "paper_abstract = ' '.join(paper_abstract.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d804c63-dfd6-4a32-9715-ac2064b080f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## download BaBar Phys. Rev. D 86 (2012) 032013 suppl. mat.\n",
    "##\n",
    "# babar_data_url = \"\"\"\\\n",
    "# http://ftp.aip.org/\\\n",
    "# epaps/phys_rev_lett/E-PRLTAO-103-045950/BABAR_ISR2pi_EPAPS.txt\\\n",
    "# \"\"\"\n",
    "# tmpfile, headers = urllib.request.urlretrieve(babar_data_url)\n",
    "# tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4001d2a-b87d-479f-adc2-7468be042341",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## if public repository not available\n",
    "## must download with authentication from PRD supplementary material archive\n",
    "## https://journals.aps.org/prd/supplemental/10.1103/PhysRevD.86.032013\n",
    "## and place the file in the location below\n",
    "##\n",
    "babar_data_url = \"https://journals.aps.org/prd/supplemental/10.1103/PhysRevD.86.032013\"\n",
    "tmpfile = \"babar-2012/BABAR_ISR2pi_EPAPS.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8927a773-1c8c-479b-9435-284e55e6e8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_l</th>\n",
       "      <th>E_h</th>\n",
       "      <th>sigma_val</th>\n",
       "      <th>sigma_unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>25.490436</td>\n",
       "      <td>2.699430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>35.480116</td>\n",
       "      <td>2.914640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>45.485797</td>\n",
       "      <td>3.046690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>51.782467</td>\n",
       "      <td>3.133550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>64.415646</td>\n",
       "      <td>3.499530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.047650</td>\n",
       "      <td>0.018634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.024211</td>\n",
       "      <td>0.013667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2.70</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>0.014118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.013260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.012373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      E_l   E_h  sigma_val  sigma_unc\n",
       "0    0.30  0.31  25.490436   2.699430\n",
       "1    0.31  0.32  35.480116   2.914640\n",
       "2    0.32  0.33  45.485797   3.046690\n",
       "3    0.33  0.34  51.782467   3.133550\n",
       "4    0.34  0.35  64.415646   3.499530\n",
       "..    ...   ...        ...        ...\n",
       "332  2.50  2.60   0.047650   0.018634\n",
       "333  2.60  2.70   0.024211   0.013667\n",
       "334  2.70  2.80   0.013945   0.014118\n",
       "335  2.80  2.90   0.009181   0.013260\n",
       "336  2.90  3.00   0.010228   0.012373\n",
       "\n",
       "[337 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## read cross-section values and uncertainties by energy bins\n",
    "##\n",
    "sigma_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  names=[\"E_l\", \"colon\", \"E_h\", \"sigma_val\", \"sigma_unc\"],\n",
    "  skiprows=29, nrows=337, sep=\"\\s+\"\n",
    ")\n",
    "sigma_df.drop(columns=\"colon\", inplace=True)\n",
    "sigma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba47794-2f97-4219-820c-b897aa3ad213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_l</th>\n",
       "      <th>E_h</th>\n",
       "      <th>unc_syst_perc_tot</th>\n",
       "      <th>unc_syst_perc_1</th>\n",
       "      <th>unc_syst_perc_2</th>\n",
       "      <th>unc_syst_perc_3</th>\n",
       "      <th>unc_syst_perc_4</th>\n",
       "      <th>unc_syst_perc_5</th>\n",
       "      <th>unc_syst_perc_6</th>\n",
       "      <th>unc_syst_perc_7</th>\n",
       "      <th>unc_syst_perc_8</th>\n",
       "      <th>unc_syst_perc_9</th>\n",
       "      <th>unc_syst_perc_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   E_l  E_h  unc_syst_perc_tot  unc_syst_perc_1  unc_syst_perc_2  \\\n",
       "0  0.3  0.4               1.38             0.53             0.38   \n",
       "1  0.4  0.5               0.81             0.27             0.21   \n",
       "2  0.5  0.6               1.02             0.19             0.21   \n",
       "3  0.6  0.9               0.50             0.10             0.11   \n",
       "4  0.9  1.2               0.65             0.05             0.17   \n",
       "5  1.2  1.4               1.39             0.04             0.31   \n",
       "6  1.4  2.0               1.98             0.03             0.31   \n",
       "7  2.0  3.0               5.24             0.03             0.31   \n",
       "\n",
       "   unc_syst_perc_3  unc_syst_perc_4  unc_syst_perc_5  unc_syst_perc_6  \\\n",
       "0             1.01             0.35             0.16             0.09   \n",
       "1             0.25             0.43             0.16             0.09   \n",
       "2             0.62             0.52             0.10             0.03   \n",
       "3             0.24             0.10             0.10             0.03   \n",
       "4             0.42             0.30             0.16             0.09   \n",
       "5             1.01             0.70             0.16             0.09   \n",
       "6             1.01             1.20             0.16             0.09   \n",
       "7             1.01             5.00             0.16             0.09   \n",
       "\n",
       "   unc_syst_perc_7  unc_syst_perc_8  unc_syst_perc_9  unc_syst_perc_10  \n",
       "0             0.30             0.27             0.10              0.34  \n",
       "1             0.20             0.14             0.27              0.34  \n",
       "2             0.30             0.16             0.27              0.34  \n",
       "3             0.13             0.11             0.10              0.34  \n",
       "4             0.20             0.13             0.13              0.34  \n",
       "5             0.30             0.27             0.10              0.34  \n",
       "6             1.00             0.51             0.10              0.34  \n",
       "7             1.00             0.51             0.10              0.34  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## read systematics\n",
    "##\n",
    "\n",
    "##\n",
    "## read edges of E for systematics, one line with\n",
    "## series of \"El-Eh\" fields\n",
    "## \n",
    "tmp_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=387, nrows=1, sep=\"\\s+\"\n",
    ")\n",
    "##\n",
    "## transform single row fields in a series of rows with each \"El-Eh\"\n",
    "## transform rows into CSV file with colums El, Eh\n",
    "##\n",
    "sigma_syst_df = pd.read_csv(\n",
    "  io.StringIO(\"\\n\".join(tmp_df.iloc[0])),\n",
    "  header=None,\n",
    "  names=[\"E_l\", \"E_h\"],\n",
    "  sep=\"-\"\n",
    ")\n",
    "sigma_syst_df\n",
    "\n",
    "##\n",
    "## read total systematics for E bins in permille\n",
    "##\n",
    "tmp_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=400, nrows=1, sep=\"\\s+\"\n",
    ")\n",
    "## read one column with total syst unc\n",
    "tmp_df = pd.read_csv(\n",
    "  io.StringIO(re.sub(\"[\\(\\)]\", \"\", \"\\n\".join(tmp_df.iloc[0]))),\n",
    "  header=None\n",
    ")\n",
    "\n",
    "sigma_syst_df = sigma_syst_df.assign(unc_syst_perc_tot = tmp_df/10)\n",
    "\n",
    "##\n",
    "## read systematics table in permille\n",
    "##\n",
    "tmp_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=389, nrows=10, sep=\"\\s+\",\n",
    ")\n",
    "##--- get data by energy bin rows\n",
    "tmp_df = tmp_df.drop(0, axis=1).transpose()\n",
    "##--- add columns with syst unc contributions\n",
    "tmp_df.columns = [\"unc_syst_perc_%d\" % i for i in range(1, 10+1)]\n",
    "for column in tmp_df:\n",
    "  sigma_syst_df = sigma_syst_df.assign(tmp_label = tmp_df[column].values/10)\n",
    "  sigma_syst_df.rename({\"tmp_label\": column}, axis=1, inplace=True)\n",
    "  \n",
    "sigma_syst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac1a008-4700-4ebe-9fcf-0ba2ba6fc692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_l_r</th>\n",
       "      <th>E_h_r</th>\n",
       "      <th>E_l_c</th>\n",
       "      <th>E_h_c</th>\n",
       "      <th>cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>7.164117e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.112126e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.924933e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.160734e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.264122e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113564</th>\n",
       "      <td>2.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.793598e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113565</th>\n",
       "      <td>2.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.110301e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113566</th>\n",
       "      <td>2.70</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.148924e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113567</th>\n",
       "      <td>2.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113568</th>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.530000e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113569 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        E_l_r  E_h_r  E_l_c  E_h_c           cov\n",
       "0        0.30   0.31    0.3   0.31  7.164117e+00\n",
       "1        0.31   0.32    0.3   0.31  8.112126e-01\n",
       "2        0.32   0.33    0.3   0.31  2.924933e-02\n",
       "3        0.33   0.34    0.3   0.31  2.160734e-01\n",
       "4        0.34   0.35    0.3   0.31  5.264122e-02\n",
       "...       ...    ...    ...    ...           ...\n",
       "113564   2.50   2.60    2.9   3.00  1.793598e-13\n",
       "113565   2.60   2.70    2.9   3.00  1.110301e-13\n",
       "113566   2.70   2.80    2.9   3.00  1.148924e-13\n",
       "113567   2.80   2.90    2.9   3.00  4.000000e-06\n",
       "113568   2.90   3.00    2.9   3.00  1.530000e-04\n",
       "\n",
       "[113569 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## get stat unc correlation\n",
    "##\n",
    "\n",
    "sigma_stat_cov_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=405, nrows=337*337, sep=\"\\s+\",\n",
    "  names=[\"cov\"]\n",
    ")\n",
    "\n",
    "## sigma_stat_corr_df\n",
    "\n",
    "sigma_stat_cov_df.insert(0, \"E_l_r\", np.tile(sigma_df.E_l.values, len(sigma_df.E_l)))\n",
    "sigma_stat_cov_df.insert(1, \"E_h_r\", np.tile(sigma_df.E_h.values, len(sigma_df.E_h)))\n",
    "sigma_stat_cov_df.insert(2, \"E_l_c\", np.repeat(sigma_df.E_l.values, len(sigma_df.E_l)))\n",
    "sigma_stat_cov_df.insert(3, \"E_h_c\", np.repeat(sigma_df.E_h.values, len(sigma_df.E_h)))\n",
    "\n",
    "sigma_stat_cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1844080-765a-4356-a0c6-946187e9b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## HEPData information that is common across tables\n",
    "##\n",
    "\n",
    "keyw_observables = [\"SIG\"]\n",
    "keyw_cmenergies = [\"0.3-3.0\"]\n",
    "keyw_reactions = [\"E+ E- --> PI+ PI-\"]\n",
    "keyw_phrases = [\n",
    "  \"Exclusive\",\n",
    "  \"E+E- Scattering\",\n",
    "  \"Integrated Cross Section\",\n",
    "  \"Cross Section\"\n",
    "]\n",
    "\n",
    "qual_sqrt_s = \"0.3-3.0\"\n",
    "qual_re = \"E+ E- --> PI+ PI-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5abeb86b-895e-4435-9f3b-85c76b6b1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## bare cross section value and total uncertainty\n",
    "##\n",
    "\n",
    "table_val = Table(\"Bare cross-section\")\n",
    "table_val.description = \"Bare cross section of $e^+e^-\\\\rightarrow\\pi^+\\pi^-(\\gamma)$\"\n",
    "table_val.location = \"Data from \" + babar_data_url\n",
    "\n",
    "table_val.keywords[\"observables\"] = [\"SIG\"]\n",
    "table_val.keywords[\"cmenergies\"] = keyw_cmenergies\n",
    "table_val.keywords[\"reactions\"] = keyw_reactions\n",
    "table_val.keywords[\"phrases\"] = keyw_phrases\n",
    "\n",
    "##--- independent variable: energy bins\n",
    "val_x = Variable(\"SQRT(S)\", is_independent=True, is_binned=True, units=\"GeV\")\n",
    "val_x.values = np.column_stack((sigma_df[\"E_l\"], sigma_df[\"E_h\"]))\n",
    "\n",
    "##--- dependent variable: bare cross-section vs. energy bin\n",
    "val_y = Variable(\"$\\sigma_{\\pi^+\\pi^-(\\gamma)}$\",  is_independent=False, is_binned=False, units=\"nb\")\n",
    "val_y.values = sigma_df[\"sigma_val\"]\n",
    "val_y.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "val_y.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "##--- uncertainty of above variable\n",
    "val_y_unc = Uncertainty(\"total\", is_symmetric=True)\n",
    "val_y_unc.values = sigma_df[\"sigma_unc\"]\n",
    "val_y.add_uncertainty(val_y_unc)\n",
    "\n",
    "##--- assemble HEPDATA table\n",
    "table_val.add_variable(val_x)\n",
    "table_val.add_variable(val_y)\n",
    "## table_val.add_image(\"image.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05aaa2b8-a978-428f-8252-ab42e71366dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## systematic uncertainty\n",
    "##\n",
    "\n",
    "table_syst_unc = Table(\"Systematic uncertainty of bare cross-section\")\n",
    "table_syst_unc.description = \"\"\"\\\n",
    "Systematic uncertainties of bare cross-section of \\\n",
    "$e^+e^-\\\\rightarrow\\pi^+\\pi^-(\\gamma)$\n",
    "all systematics contributions are each 100% correlated in all energy bins\\\n",
    "\"\"\"\n",
    "table_syst_unc.location = \"Data from \" + babar_data_url\n",
    "\n",
    "table_syst_unc.keywords[\"observables\"] = keyw_observables\n",
    "table_syst_unc.keywords[\"cmenergies\"] = keyw_cmenergies\n",
    "table_syst_unc.keywords[\"reactions\"] = keyw_reactions\n",
    "table_syst_unc.keywords[\"phrases\"] = keyw_phrases\n",
    "\n",
    "syst_unc_x = Variable(\"SQRT(S) [GeV]\", is_independent=True, is_binned=True)\n",
    "syst_unc_x.values = np.column_stack((sigma_syst_df[\"E_l\"], sigma_syst_df[\"E_h\"]))\n",
    "\n",
    "syst_unc_y = Variable(\n",
    "  \"total\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y.values = sigma_syst_df[\"unc_syst_perc_tot\"]\n",
    "syst_unc_y.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "# Sources  1   trigger / filter \n",
    "#          2   tracking\n",
    "#          3   pi-ID\n",
    "#          4   background\n",
    "#          5   acceptance\n",
    "#          6   kinematic fit chi2 cut\n",
    "#          7   correlated mu mu ID loss\n",
    "#          8   non cancellation of HO ISR in pi pi gamma/mu mu gamma ratio\n",
    "#          9   unfolding\n",
    "#         10   ISR luminosity from mu mu gamma process\n",
    "\n",
    "syst_unc_y1 = Variable(\n",
    "  \"trigger / filter \",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y1.values = sigma_syst_df[\"unc_syst_perc_1\"]\n",
    "syst_unc_y1.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y1.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y2 = Variable(\n",
    "  \"tracking\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y2.values = sigma_syst_df[\"unc_syst_perc_2\"]\n",
    "syst_unc_y2.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y2.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y3 = Variable(\n",
    "  \"pi-ID\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y3.values = sigma_syst_df[\"unc_syst_perc_3\"]\n",
    "syst_unc_y3.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y3.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y4 = Variable(\n",
    "  \"background\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y4.values = sigma_syst_df[\"unc_syst_perc_4\"]\n",
    "syst_unc_y4.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y4.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y5 = Variable(\n",
    "  \"acceptance\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y5.values = sigma_syst_df[\"unc_syst_perc_5\"]\n",
    "syst_unc_y5.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y5.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y6 = Variable(\n",
    "  \"kinematic fit chi2 cut\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y6.values = sigma_syst_df[\"unc_syst_perc_6\"]\n",
    "syst_unc_y6.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y6.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y7 = Variable(\n",
    "  \"correlated mu mu ID loss\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y7.values = sigma_syst_df[\"unc_syst_perc_7\"]\n",
    "syst_unc_y7.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y7.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y8 = Variable(\n",
    "  \"non cancellation of HO ISR in pi pi gamma/mu mu gamma ratio\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y8.values = sigma_syst_df[\"unc_syst_perc_8\"]\n",
    "syst_unc_y8.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y8.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y9 = Variable(\n",
    "  \"unfolding\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y9.values = sigma_syst_df[\"unc_syst_perc_9\"]\n",
    "syst_unc_y9.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y9.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "syst_unc_y10 = Variable(\n",
    "  \"ISR luminosity from mu mu gamma process\",\n",
    "  is_independent=False, is_binned=False, units=\"%\"\n",
    ")\n",
    "syst_unc_y10.values = sigma_syst_df[\"unc_syst_perc_10\"]\n",
    "syst_unc_y10.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "syst_unc_y10.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "for var in [\n",
    "    syst_unc_x, syst_unc_y,\n",
    "    syst_unc_y1, syst_unc_y2, syst_unc_y3, syst_unc_y4, syst_unc_y5,\n",
    "    syst_unc_y6, syst_unc_y7, syst_unc_y8, syst_unc_y9, syst_unc_y10\n",
    "  ]:\n",
    "  table_syst_unc.add_variable(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045ffa92-c05f-42ed-9e00-e51a2b2e01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## statistical covariance\n",
    "##\n",
    "\n",
    "table_stat_cov = Table(\"Statistical covariance of bare cross-section\")\n",
    "table_stat_cov.description = \"\"\"\\\n",
    "Statistical covariance of bare cross-section of \\\n",
    "$e^+e^-\\\\rightarrow\\pi^+\\pi^-(\\gamma)$\\\n",
    "\"\"\"\n",
    "table_stat_cov.location = \"Data from \" + babar_data_url\n",
    "\n",
    "table_stat_cov.keywords[\"observables\"] = keyw_observables\n",
    "table_stat_cov.keywords[\"cmenergies\"] = keyw_cmenergies\n",
    "table_stat_cov.keywords[\"reactions\"] = keyw_reactions\n",
    "table_stat_cov.keywords[\"phrases\"] = keyw_phrases\n",
    "\n",
    "##--- independent variables: row and column energy bins\n",
    "stat_cov_x = Variable(\"SQRT(S) [GeV]\", is_independent=True, is_binned=True)\n",
    "stat_cov_x.values = np.column_stack((sigma_stat_cov_df[\"E_l_r\"], sigma_stat_cov_df[\"E_h_r\"]))\n",
    "stat_cov_y = Variable(\"SQRT(S) [GeV]\", is_independent=True, is_binned=True)\n",
    "stat_cov_y.values = np.column_stack((sigma_stat_cov_df[\"E_l_c\"], sigma_stat_cov_df[\"E_h_c\"]))\n",
    "\n",
    "##--- correlation of cross section in one energy bin w.r.t. another energy bin\n",
    "stat_cov_z = Variable(\n",
    "  \"$\\sigma_{\\pi^+\\pi^-(\\gamma)}$ statistical covariance\",\n",
    "  is_independent=False, is_binned=False, units=\"nb^2\"\n",
    ")\n",
    "stat_cov_z.values = sigma_stat_cov_df[\"cov\"]\n",
    "stat_cov_z.add_qualifier(\"SQRT(S)\", qual_sqrt_s, \"GeV\")\n",
    "stat_cov_z.add_qualifier(\"RE\", qual_re)\n",
    "\n",
    "for var in [stat_cov_x, stat_cov_y, stat_cov_z]:\n",
    "  table_stat_cov.add_variable(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dafcdb9-8ec0-4473-ab4f-3d1a9ed49939",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## assembly and submission\n",
    "##\n",
    "\n",
    "hd_subm = Submission()\n",
    "\n",
    "##--- general info\n",
    "hd_subm.add_record_id(1114155, \"inspire\")\n",
    "hd_subm.add_link(\"arXiv\", \"https://arxiv.org/abs/1205.2228\")\n",
    "hd_subm.add_link(\"Webpage with data files\", babar_data_url)\n",
    "\n",
    "##--- use temp file for abstract\n",
    "tmp = tempfile.NamedTemporaryFile(mode='w+t', delete=False)\n",
    "try:\n",
    "  tmp.writelines(paper_abstract)\n",
    "finally:\n",
    "  tmp.close()\n",
    "hd_subm.read_abstract(tmp.name)\n",
    "\n",
    "##--- add tables\n",
    "hd_subm.add_table(table_val)\n",
    "hd_subm.add_table(table_syst_unc)\n",
    "hd_subm.add_table(table_stat_cov)\n",
    "\n",
    "##---\n",
    "outdir = \"babar-pip-pim-2012-insp1114155-hdsubm\"\n",
    "hd_subm.create_files(outdir)\n",
    "os.unlink(tmp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3339062-5c84-4362-9949-dcc3f0e61c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "all,-widgets,-varInspector,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nikola": {
   "category": "submissions",
   "date": "2021-11-22 12:00:00 UTC",
   "has_math": "true",
   "tags": [
    "BaBar",
    "HEPData"
   ],
   "title": "Submit HEPData BaBar 2012 ùúé(ùëí+ùëí‚àí ‚Üí ùúã+ùúã‚àí(ùõæ))"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

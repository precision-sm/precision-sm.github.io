{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3874ee-a795-4b7a-ae91-dea7381f83aa",
   "metadata": {},
   "source": [
    "<!-- TEASER_END -->\n",
    "# HEPData submit BaBar 2012 $\\sigma(e^+e^- \\to \\pi^+ \\pi^- (\\gamma))$\n",
    "\n",
    "## Paper\n",
    "\n",
    "- [Phys.Rev.D 86 (2012) 032013, 2012](https://doi.org/10.1103/PhysRevD.86.032013)\n",
    "- [InspireHEP 1114155](https://inspirehep.net/literature/1114155)\n",
    "\n",
    "## HEPData documentation for submissions\n",
    "\n",
    "- [https://hepdata-submission.readthedocs.io/en/latest/](https://hepdata-submission.readthedocs.io/en/latest/)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- [hepdata_lib](https://github.com/HEPData/hepdata_lib) python3 library\n",
    "  - [ROOT](https://root.cern.ch) with Python3 libraries\n",
    "  - [ImageMagick](https://www.imagemagick.org)\n",
    "  - Make sure that you have `ROOT` in your `$PYTHONPATH` and that the `convert` command is available by adding its location to your `$PATH` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbe9b162-0f47-41cb-8726-d0f07740d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "from array import array\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from requests.utils import requote_uri\n",
    "import json\n",
    "import yaml\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0ac8a2e-4235-4cb3-b056-9c16a545e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hepdata_lib\n",
    "from hepdata_lib import Submission\n",
    "from hepdata_lib import Table\n",
    "from hepdata_lib import Variable, Uncertainty\n",
    "from hepdata_lib import RootFileReader\n",
    "from hepdata_lib import root_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af3bed9c-c99a-41b6-88d1-d3d927ab8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## globals\n",
    "##\n",
    "\n",
    "myfolder = Path(\"hepdata-babar-2012-pip-pim\")\n",
    "if not os.path.exists(myfolder):\n",
    "  os.makedirs(myfolder)\n",
    "\n",
    "suppmat_fname = \"BABAR_ISR2pi_EPAPS.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3980ecde-766a-4321-9e7b-7b3c666fa416",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## procedures\n",
    "##\n",
    "\n",
    "@contextmanager\n",
    "def cd(newdir):\n",
    "  prevdir = os.getcwd()\n",
    "  os.chdir(os.path.expanduser(newdir))\n",
    "  try:\n",
    "    yield\n",
    "  finally:\n",
    "    os.chdir(prevdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a9462e7-0354-4a79-b0e4-9cbd9a281fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## abstract\n",
    "##\n",
    "paper_abstract = r\"\"\"A precise measurement of the cross section of the process $e^+e^- \\to\n",
    "\\pi^+\\pi^-(\\gamma)$ from threshold to an energy of $3$ GeV is obtained with the\n",
    "initial-state radiation (ISR) method using $232$ fb$^{-1}$ of data collected\n",
    "with the BaBar detector at $e^+e^-$ center-of-mass energies near $10.6$ GeV.\n",
    "The ISR luminosity is determined from a study of the leptonic process\n",
    "$e^+e^-\\to\\mu^+\\mu^-(\\gamma)\\gamma_{\\rm ISR}$, which is found to agree with the\n",
    "next-to-leading-order QED prediction to within 1.1\\%. The cross section for the\n",
    "process $e^+e^-\\to\\pi^+\\pi^-(\\gamma)$ is obtained with a systematic uncertainty\n",
    "of 0.5\\% in the dominant $\\rho$ resonance region. The leading-order hadronic\n",
    "contribution to the muon magnetic anomaly calculated using the measured\n",
    "$\\pi\\pi$ cross section from threshold to $1.8$ GeV is $(514.1 \\pm 2.2({\\rm\n",
    "stat}) \\pm 3.1({\\rm syst}))\\times 10^{-10}$.\"\"\"\n",
    "paper_abstract = ' '.join(paper_abstract.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d804c63-dfd6-4a32-9715-ac2064b080f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## download BaBar Phys. Rev. D 86 (2012) 032013 suppl. mat.\n",
    "##\n",
    "## was available without authentication until end 2021\n",
    "## but recently became unavailable\n",
    "##\n",
    "# babar_data_url = \"\"\"\\\n",
    "# http://ftp.aip.org/\\\n",
    "# epaps/phys_rev_lett/E-PRLTAO-103-045950/BABAR_ISR2pi_EPAPS.txt\\\n",
    "# \"\"\"\n",
    "# tmpfile, headers = urllib.request.urlretrieve(babar_data_url)\n",
    "# tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4001d2a-b87d-479f-adc2-7468be042341",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## download with authentication from PRD supplementary material archive\n",
    "## in https://journals.aps.org/prd/supplemental/10.1103/PhysRevD.86.032013\n",
    "## and place the file in the location in \"tmpfile\"\n",
    "##\n",
    "babar_data_url = \"https://journals.aps.org/prd/supplemental/10.1103/PhysRevD.86.032013\"\n",
    "tmpfile = myfolder / suppmat_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8927a773-1c8c-479b-9435-284e55e6e8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_l</th>\n",
       "      <th>E_h</th>\n",
       "      <th>sigma_val</th>\n",
       "      <th>sigma_unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>25.490436</td>\n",
       "      <td>2.699430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>35.480116</td>\n",
       "      <td>2.914640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>45.485797</td>\n",
       "      <td>3.046690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>51.782467</td>\n",
       "      <td>3.133550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>64.415646</td>\n",
       "      <td>3.499530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.047650</td>\n",
       "      <td>0.018634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.024211</td>\n",
       "      <td>0.013667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2.70</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>0.014118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.013260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.012373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      E_l   E_h  sigma_val  sigma_unc\n",
       "0    0.30  0.31  25.490436   2.699430\n",
       "1    0.31  0.32  35.480116   2.914640\n",
       "2    0.32  0.33  45.485797   3.046690\n",
       "3    0.33  0.34  51.782467   3.133550\n",
       "4    0.34  0.35  64.415646   3.499530\n",
       "..    ...   ...        ...        ...\n",
       "332  2.50  2.60   0.047650   0.018634\n",
       "333  2.60  2.70   0.024211   0.013667\n",
       "334  2.70  2.80   0.013945   0.014118\n",
       "335  2.80  2.90   0.009181   0.013260\n",
       "336  2.90  3.00   0.010228   0.012373\n",
       "\n",
       "[337 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## read cross-section values and uncertainties by energy bins\n",
    "##\n",
    "sigma_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  names=[\"E_l\", \"colon\", \"E_h\", \"sigma_val\", \"sigma_unc\"],\n",
    "  skiprows=29, nrows=337, sep=\"\\s+\"\n",
    ")\n",
    "sigma_df.drop(columns=\"colon\", inplace=True)\n",
    "sigma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b9eb4e4-29e8-4eef-b470-27898f7ccd70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_l</th>\n",
       "      <th>E_h</th>\n",
       "      <th>unc_syst_perc_tot</th>\n",
       "      <th>unc_syst_perc_1</th>\n",
       "      <th>unc_syst_perc_2</th>\n",
       "      <th>unc_syst_perc_3</th>\n",
       "      <th>unc_syst_perc_4</th>\n",
       "      <th>unc_syst_perc_5</th>\n",
       "      <th>unc_syst_perc_6</th>\n",
       "      <th>unc_syst_perc_7</th>\n",
       "      <th>unc_syst_perc_8</th>\n",
       "      <th>unc_syst_perc_9</th>\n",
       "      <th>unc_syst_perc_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.24</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   E_l  E_h  unc_syst_perc_tot  unc_syst_perc_1  unc_syst_perc_2  \\\n",
       "0  0.3  0.4               1.38             0.53             0.38   \n",
       "1  0.4  0.5               0.81             0.27             0.21   \n",
       "2  0.5  0.6               1.02             0.19             0.21   \n",
       "3  0.6  0.9               0.50             0.10             0.11   \n",
       "4  0.9  1.2               0.65             0.05             0.17   \n",
       "5  1.2  1.4               1.39             0.04             0.31   \n",
       "6  1.4  2.0               1.98             0.03             0.31   \n",
       "7  2.0  3.0               5.24             0.03             0.31   \n",
       "\n",
       "   unc_syst_perc_3  unc_syst_perc_4  unc_syst_perc_5  unc_syst_perc_6  \\\n",
       "0             1.01             0.35             0.16             0.09   \n",
       "1             0.25             0.43             0.16             0.09   \n",
       "2             0.62             0.52             0.10             0.03   \n",
       "3             0.24             0.10             0.10             0.03   \n",
       "4             0.42             0.30             0.16             0.09   \n",
       "5             1.01             0.70             0.16             0.09   \n",
       "6             1.01             1.20             0.16             0.09   \n",
       "7             1.01             5.00             0.16             0.09   \n",
       "\n",
       "   unc_syst_perc_7  unc_syst_perc_8  unc_syst_perc_9  unc_syst_perc_10  \n",
       "0             0.30             0.27             0.10              0.34  \n",
       "1             0.20             0.14             0.27              0.34  \n",
       "2             0.30             0.16             0.27              0.34  \n",
       "3             0.13             0.11             0.10              0.34  \n",
       "4             0.20             0.13             0.13              0.34  \n",
       "5             0.30             0.27             0.10              0.34  \n",
       "6             1.00             0.51             0.10              0.34  \n",
       "7             1.00             0.51             0.10              0.34  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## read systematics\n",
    "##\n",
    "\n",
    "##\n",
    "## BaBar data format\n",
    "##\n",
    "#              Energy Intervals (GeV)\n",
    "#          \n",
    "#    0.3-0.4  0.4-0.5  0.5-0.6  0.6-0.9  0.9-1.2  1.2-1.4  1.4-2.0  2.0-3.0\n",
    "#\n",
    "# 1    5.3      2.7      1.9      1.0      0.5      0.4      0.3      0.3 \n",
    "# 2    3.8      2.1      2.1      1.1      1.7      3.1      3.1      3.1 \n",
    "# 3   10.1      2.5      6.2      2.4      4.2     10.1     10.1     10.1\n",
    "# 4    3.5      4.3      5.2      1.0      3.0      7.0     12.0     50.0\n",
    "# 5    1.6      1.6      1.0      1.0      1.6      1.6      1.6      1.6\n",
    "# 6    0.9      0.9      0.3      0.3      0.9      0.9      0.9      0.9\n",
    "# 7    3.0      2.0      3.0      1.3      2.0      3.0     10.0     10.0\n",
    "# 8    2.7      1.4      1.6      1.1      1.3      2.7      5.1      5.1\n",
    "# 9    1.0      2.7      2.7      1.0      1.3      1.0      1.0      1.0\n",
    "# 10   3.4      3.4      3.4      3.4      3.4      3.4      3.4      3.4\n",
    "#\n",
    "#    (13.8)    (8.1)   (10.2)    (5.0)    (6.5)   (13.9)   (19.8)   (52.4) \n",
    "#\n",
    "\n",
    "##\n",
    "## read edges of E for systematics, in a single line\n",
    "## format is space-separated sequence of \"<El>-<Eh>\"\n",
    "## \n",
    "tmp_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=387, nrows=1, sep=\"\\s+\"\n",
    ")\n",
    "\n",
    "##\n",
    "## - get first row of tmp_df\n",
    "## - join first row values in a series of lines separated with newline\n",
    "## - interpret each line as two numbers separated by \"-\"\n",
    "## - output is data frame with columns El, Eh\n",
    "##\n",
    "sigma_syst_df = pd.read_csv(\n",
    "  io.StringIO(\"\\n\".join(tmp_df.iloc[0])),\n",
    "  header=None,\n",
    "  names=[\"E_l\", \"E_h\"],\n",
    "  sep=\"-\"\n",
    ")\n",
    "\n",
    "##\n",
    "## read total systematics for E bins in permille\n",
    "## sequence of numbers in round brakets\n",
    "##\n",
    "tmp_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=400, nrows=1, sep=\"\\s+\"\n",
    ")\n",
    "##--- read column with total syst unc\n",
    "tmp_df = pd.read_csv(\n",
    "  io.StringIO(re.sub(\"[\\(\\)]\", \"\", \"\\n\".join(tmp_df.iloc[0]))),\n",
    "  header=None\n",
    ")\n",
    "\n",
    "##\n",
    "## - convert total unc in 1st column from permille to percent\n",
    "## - add to data frame as 3rd column after El, Eh\n",
    "##\n",
    "sigma_syst_df = sigma_syst_df.assign(unc_syst_perc_tot = tmp_df[0]/10)\n",
    "\n",
    "##\n",
    "## read systematics contributions table in permille\n",
    "## each row is a systematics contribution\n",
    "## each column corresponds to an energy bin\n",
    "##\n",
    "tmp_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=389, nrows=10, sep=\"\\s+\",\n",
    ")\n",
    "\n",
    "##\n",
    "## - drop first column with number of systematic contribution\n",
    "## - transpose to get energy bins in rows, contribution in columns\n",
    "## \n",
    "tmp_df = tmp_df.drop(0, axis=1).transpose()\n",
    "##--- add columns with syst unc contributions\n",
    "tmp_df.columns = [\"unc_syst_perc_%d\" % i for i in range(1, 10+1)]\n",
    "for column in tmp_df:\n",
    "  ##--- add syst contribution on col name = \"tmp_label\"\n",
    "  sigma_syst_df = sigma_syst_df.assign(tmp_label = tmp_df[column].values/10)\n",
    "  ##--- rename \"tmp_label\" to unc_syst_perc_%d\n",
    "  sigma_syst_df.rename({\"tmp_label\": column}, axis=1, inplace=True)\n",
    "  \n",
    "sigma_syst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aac1a008-4700-4ebe-9fcf-0ba2ba6fc692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_l_r</th>\n",
       "      <th>E_h_r</th>\n",
       "      <th>E_l_c</th>\n",
       "      <th>E_h_c</th>\n",
       "      <th>cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>7.164117e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.112126e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.924933e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.160734e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.264122e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113564</th>\n",
       "      <td>2.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.793598e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113565</th>\n",
       "      <td>2.60</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.110301e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113566</th>\n",
       "      <td>2.70</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.148924e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113567</th>\n",
       "      <td>2.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113568</th>\n",
       "      <td>2.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.530000e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113569 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        E_l_r  E_h_r  E_l_c  E_h_c           cov\n",
       "0        0.30   0.31    0.3   0.31  7.164117e+00\n",
       "1        0.31   0.32    0.3   0.31  8.112126e-01\n",
       "2        0.32   0.33    0.3   0.31  2.924933e-02\n",
       "3        0.33   0.34    0.3   0.31  2.160734e-01\n",
       "4        0.34   0.35    0.3   0.31  5.264122e-02\n",
       "...       ...    ...    ...    ...           ...\n",
       "113564   2.50   2.60    2.9   3.00  1.793598e-13\n",
       "113565   2.60   2.70    2.9   3.00  1.110301e-13\n",
       "113566   2.70   2.80    2.9   3.00  1.148924e-13\n",
       "113567   2.80   2.90    2.9   3.00  4.000000e-06\n",
       "113568   2.90   3.00    2.9   3.00  1.530000e-04\n",
       "\n",
       "[113569 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## get stat unc correlation\n",
    "## it is a sequence of 337*337 values\n",
    "##\n",
    "\n",
    "sigma_stat_cov_df = pd.read_csv(\n",
    "  tmpfile,\n",
    "  header=None,\n",
    "  skiprows=405, nrows=337*337, sep=\"\\s+\",\n",
    "  names=[\"cov\"]\n",
    ")\n",
    "\n",
    "## sigma_stat_corr_df\n",
    "\n",
    "##\n",
    "## insert data frame columns with lo-hi row energy bin, lo-hi column energy bin\n",
    "## (very verbose inefficient format but prepared for HEPData format)\n",
    "##\n",
    "sigma_stat_cov_df.insert(0, \"E_l_r\", np.tile(sigma_df.E_l.values, len(sigma_df.E_l)))\n",
    "sigma_stat_cov_df.insert(1, \"E_h_r\", np.tile(sigma_df.E_h.values, len(sigma_df.E_h)))\n",
    "sigma_stat_cov_df.insert(2, \"E_l_c\", np.repeat(sigma_df.E_l.values, len(sigma_df.E_l)))\n",
    "sigma_stat_cov_df.insert(3, \"E_h_c\", np.repeat(sigma_df.E_h.values, len(sigma_df.E_h)))\n",
    "\n",
    "sigma_stat_cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1844080-765a-4356-a0c6-946187e9b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## HEPData information that is common across tables\n",
    "##\n",
    "\n",
    "keyw_observables = [\"SIG\"]\n",
    "keyw_cmenergies = [\"0.3-3.0\"]\n",
    "keyw_reactions = [\"E+ E- --> PI+ PI-\"]\n",
    "keyw_phrases = [\n",
    "  \"Exclusive\",\n",
    "  \"E+E- Scattering\",\n",
    "  \"Integrated Cross Section\",\n",
    "  \"Cross Section\"\n",
    "]\n",
    "\n",
    "##\n",
    "## all measurements\n",
    "## - refer to reaction = \"E+ E- --> PI+ PI-\"\n",
    "## - are valued as function of energy\n",
    "##\n",
    "def set_var_qualif(var):\n",
    "  var.add_qualifier(\"RE\", \"E+ E- --> PI+ PI-\")\n",
    "  var.add_qualifier(\"SQRT(S)\", \"0.3-3.0\", \"GeV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5abeb86b-895e-4435-9f3b-85c76b6b1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## bare cross section value and total uncertainty\n",
    "##\n",
    "\n",
    "table_val = Table(\"Bare cross-section\")\n",
    "table_val.description = \"Bare cross section of $e^+e^-\\\\rightarrow\\pi^+\\pi^-(\\gamma)$\"\n",
    "table_val.location = \"Data from \" + babar_data_url\n",
    "\n",
    "table_val.keywords[\"observables\"] = keyw_observables\n",
    "table_val.keywords[\"cmenergies\"] = keyw_cmenergies\n",
    "table_val.keywords[\"reactions\"] = keyw_reactions\n",
    "table_val.keywords[\"phrases\"] = keyw_phrases\n",
    "\n",
    "##--- independent variable: energy bins\n",
    "val_x = Variable(\"SQRT(S)\", is_independent=True, is_binned=True, units=\"GeV\")\n",
    "val_x.values = np.column_stack((sigma_df[\"E_l\"], sigma_df[\"E_h\"]))\n",
    "\n",
    "##--- dependent variable: bare cross-section vs. energy bin\n",
    "val_y = Variable(\"$\\sigma_{\\pi^+\\pi^-(\\gamma)}$\",  is_independent=False, is_binned=False, units=\"nb\")\n",
    "val_y.values = sigma_df[\"sigma_val\"]\n",
    "set_var_qualif(val_y)\n",
    "\n",
    "##--- uncertainty of above variable\n",
    "val_y_unc = Uncertainty(\"total\", is_symmetric=True)\n",
    "val_y_unc.values = sigma_df[\"sigma_unc\"]\n",
    "val_y.add_uncertainty(val_y_unc)\n",
    "\n",
    "##--- assemble HEPDATA table\n",
    "table_val.add_variable(val_x)\n",
    "table_val.add_variable(val_y)\n",
    "## table_val.add_image(\"image.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dbc0c02-f10d-4c37-9c86-5dcaef3780be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## systematic uncertainty\n",
    "##\n",
    "\n",
    "table_syst_unc = Table(\"Systematic uncertainty of bare cross-section\")\n",
    "table_syst_unc.description = \"\"\"\\\n",
    "Systematic uncertainties of bare cross-section of \\\n",
    "$e^+e^-\\\\rightarrow\\pi^+\\pi^-(\\gamma)$\n",
    "all systematics contributions are each 100% correlated in all energy bins\\\n",
    "\"\"\"\n",
    "table_syst_unc.location = \"Data from \" + babar_data_url\n",
    "\n",
    "table_syst_unc.keywords[\"observables\"] = keyw_observables\n",
    "table_syst_unc.keywords[\"cmenergies\"] = keyw_cmenergies\n",
    "table_syst_unc.keywords[\"reactions\"] = keyw_reactions\n",
    "table_syst_unc.keywords[\"phrases\"] = keyw_phrases\n",
    "\n",
    "syst_unc_x = Variable(\"SQRT(S) [GeV]\", is_independent=True, is_binned=True)\n",
    "syst_unc_x.values = np.column_stack((sigma_syst_df[\"E_l\"], sigma_syst_df[\"E_h\"]))\n",
    "\n",
    "##\n",
    "## systematics contributions\n",
    "## (and first colums is total unc)\n",
    "##\n",
    "syst_contr_descr = [\n",
    "  \"trigger / filter\",\n",
    "  \"tracking\",\n",
    "  \"pi-ID\",\n",
    "  \"background\",\n",
    "  \"acceptance\",\n",
    "  \"kinematic fit chi2 cut\",\n",
    "  \"correlated mu mu ID loss\",\n",
    "  \"non cancellation of HO ISR in pi pi gamma/mu mu gamma ratio\",\n",
    "  \"unfolding\",\n",
    "  \"ISR luminosity from mu mu gamma process\",\n",
    "]\n",
    "\n",
    "##\n",
    "## create a HEPData var for syst unc total and contributions\n",
    "##\n",
    "vars = []\n",
    "for descr, suff in zip(\n",
    "  [\"total\"] + syst_contr_descr,\n",
    "  [\"tot\"] + [str(i-2) for i in range(3, sigma_syst_df.shape[1])],\n",
    "):\n",
    "  syst_unc_y = Variable(\n",
    "    descr,\n",
    "    is_independent=False, is_binned=False, units=\"%\"\n",
    "  )\n",
    "  syst_unc_y.values = sigma_syst_df[\"unc_syst_perc_\" + suff]\n",
    "  set_var_qualif(syst_unc_y)\n",
    "  vars.append(syst_unc_y)\n",
    "\n",
    "##--- add all defined vars to submission\n",
    "for var in [syst_unc_x] + vars:\n",
    "  table_syst_unc.add_variable(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "045ffa92-c05f-42ed-9e00-e51a2b2e01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## statistical covariance\n",
    "##\n",
    "\n",
    "table_stat_cov = Table(\"Statistical covariance of bare cross-section\")\n",
    "table_stat_cov.description = \"\"\"\\\n",
    "Statistical covariance of bare cross-section of \\\n",
    "$e^+e^-\\\\rightarrow\\pi^+\\pi^-(\\gamma)$\\\n",
    "\"\"\"\n",
    "table_stat_cov.location = \"Data from \" + babar_data_url\n",
    "\n",
    "table_stat_cov.keywords[\"observables\"] = keyw_observables\n",
    "table_stat_cov.keywords[\"cmenergies\"] = keyw_cmenergies\n",
    "table_stat_cov.keywords[\"reactions\"] = keyw_reactions\n",
    "table_stat_cov.keywords[\"phrases\"] = keyw_phrases\n",
    "\n",
    "##--- independent variables: row and column energy bins\n",
    "stat_cov_x = Variable(\"SQRT(S) [GeV]\", is_independent=True, is_binned=True)\n",
    "stat_cov_x.values = np.column_stack((sigma_stat_cov_df[\"E_l_r\"], sigma_stat_cov_df[\"E_h_r\"]))\n",
    "stat_cov_y = Variable(\"SQRT(S) [GeV]\", is_independent=True, is_binned=True)\n",
    "stat_cov_y.values = np.column_stack((sigma_stat_cov_df[\"E_l_c\"], sigma_stat_cov_df[\"E_h_c\"]))\n",
    "\n",
    "##--- correlation of cross section in one energy bin w.r.t. another energy bin\n",
    "stat_cov_z = Variable(\n",
    "  \"$\\sigma_{\\pi^+\\pi^-(\\gamma)}$ statistical covariance\",\n",
    "  is_independent=False, is_binned=False, units=\"nb^2\"\n",
    ")\n",
    "stat_cov_z.values = sigma_stat_cov_df[\"cov\"]\n",
    "set_var_qualif(stat_cov_z)\n",
    "\n",
    "for var in [stat_cov_x, stat_cov_y, stat_cov_z]:\n",
    "  table_stat_cov.add_variable(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dafcdb9-8ec0-4473-ab4f-3d1a9ed49939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating submission in hepdata-babar-2012-pip-pim/submission.tar.gz\n",
      "submission created\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## assembly and submission\n",
    "##\n",
    "\n",
    "##--- all output will go here\n",
    "with cd(myfolder):\n",
    "  print(\"creating submission in \" + str(myfolder / \"submission.tar.gz\"))\n",
    "  hd_subm = Submission()\n",
    "\n",
    "  ##--- general info\n",
    "  hd_subm.add_record_id(1114155, \"inspire\")\n",
    "  hd_subm.add_link(\"arXiv\", \"https://arxiv.org/abs/1205.2228\")\n",
    "  hd_subm.add_link(\"Webpage with data files\", babar_data_url)\n",
    "\n",
    "  ##--- use temp file for abstract\n",
    "  tmp = tempfile.NamedTemporaryFile(mode='w+t', delete=False)\n",
    "  try:\n",
    "    tmp.writelines(paper_abstract)\n",
    "  finally:\n",
    "    tmp.close()\n",
    "  hd_subm.read_abstract(tmp.name)\n",
    "\n",
    "  ##--- add tables\n",
    "  hd_subm.add_table(table_val)\n",
    "  hd_subm.add_table(table_syst_unc)\n",
    "  hd_subm.add_table(table_stat_cov)\n",
    "\n",
    "  ##--- create submission\n",
    "  outdir = \"submission\"\n",
    "  hd_subm.create_files(outdir)\n",
    "  os.unlink(tmp.name)\n",
    "\n",
    "print(\"submission created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544a046-dabc-473a-8748-9d67349a2e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "all,-widgets,-varInspector,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nikola": {
   "category": "submissions",
   "date": "2021-11-22 12:00:00 UTC",
   "has_math": "true",
   "tags": [
    "BaBar",
    "HEPData"
   ],
   "title": "Submit HEPData BaBar 2012 $\\sigma(e^+e^- \\rightarrow \\pi^+\\pi^- (\\gamma))$"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
